import sys
import random 
import math
import numpy as np
from math import exp

#filename=sys.stdin
filename=open('cleaned.data','r')
rows=[]

for line in filename:
	line=line.strip()
	line=line.split(',')
	for j in range(len(line)):
		line[j]=int(line[j])
	rows.append(line)

def convert(all_rows):
	for row in all_rows:
		for j in range(0,11):
			row[j]=int(row[j])

def k_fold_validation(all_rows,k):
	convert(all_rows)
	split_list=[]
	dataset=all_rows
	split_size=len(all_rows)/k
	split_size=int(split_size)

	for i in range(k):
		split=[]
		while(len(split)<split_size):
			j=random.randrange(0,len(all_rows))
			row=all_rows[j]
			split.append(row)
			split_list.append(row)
			removed_row=dataset.pop(j)
		#split_list.append(split)
	return split_list


#calculate min-max for each column
def maxmin(data):
	mm=[]
	for i in range(1,len(data[1])):
		c=[]
		for j in range(len(data)):
			for i in range(len(data[j])):
				if i==0:
					pass
					
				else:
					#print(data[j][i])
					c.append(data[j][i])
				#print(c)
		maxx=max(c)
		minn=min(c)
		mm.append([maxx,minn])
	return mm

def make_splits(split_list):
	trainset=[]
	testset=[]
	for i in split_list:
		trainset.append(i)
		
		#print(i)
		l=[]
		for j in range(len(i)):
			
			if(j==10):
				pass
			else:
				l.append(i[j])
		testset.append(l)
	return trainset,testset

def normalise(x,mm):
	for r in x:
		for i in range(len(r)):
			r[i]=(r[i]-mm[i][0])/(mm[i][1]-mm[i][0])
#learn_rate is used to limit the amount each coeff is corrected each time it is updated
#epochs-the number of times to run through thr training data tr while updating the coeff

#3 loops to perform in this func:
#1.loop over each epoch 
#2.loop over each row in the training set for each epoch
#3.loop over each coeff and update it for a row in an epoch
#coeff are ipdated based on the error the model makes.the error is calculated as the differemce b/w the expected output value and the prediction made with the candidate coeff
# Make a prediction with coefficients
def predict(row, coefficients):
	yhat = coefficients[0]
	for i in range(len(row)-1):
		yhat += coefficients[i + 1] * row[i]
	return 1.0 / (1.0 + exp(-yhat))


def stochasticgd(tr,epochs,learn_rate):
	'''coeff=[]
	for i in range(len(tr[0])): #check this
		coeff[i]=0	'''
	coeff = [0 for i in range(len(tr[0]))]
	print(coeff)
	
	for i in range(epochs):
		summe=0
		for j in tr:
			yh=coeff[0]
			for ii in range(len(j)-1):
				yh=yh+(coeff[ii+1]*j[ii])
			yhat=1/(1+exp(-yh)) #sigmoid
			#print(yhat)
			
			error=j[-1]-yhat
			print(error)
			
			ferr=error**2
			summe=summe+ferr
			print(summe)
			'''
			coeff[0]=coeff[0]+(error*learn_rate*yhat*(1-yhat))
			for m in range(len(j)-1):
				coeff[m+1]=coeff[m+1]+(error*learn_rate*yhat*(1-yhat)*j[m])
		print('>epoch=%d, lrate=%.3f, error=%.3f' % (i, learn_rate, summe))
	return coeff
'''
minmax=maxmin(rows)
normalise(rows,minmax)
stochasticgd(rows,1,0.1)

def logistic_regression(train, test, l_rate, n_epoch):
	predictions = list()
	coef =stochasticgd(train, l_rate, n_epoch)
	for row in test:
		yhat = predict(row, coef)
	
		yhat = round(yhat)
		predictions.append(yhat)
	return(predictions)
 
'''

def evaluate_algorithm(dataset, algorithm, n_folds, *args):
	folds = k_fold_validation(dataset, n_folds)
	scores = list()
	for fold in folds:
		train_set = list(folds)
		train_set.remove(fold)
		train_set = sum(train_set, [])
		test_set = list()
		print(fold)
		#for row in fold:
		row_copy = list(fold)
		test_set.append(row_copy)
		row_copy[-1] = None
		predicted = algorithm(train_set, test_set, *args)
		actual = [row[-1] for row in fold]
		accuracy = accuracy_metric(actual, predicted)
		scores.append(accuracy)
	return scores
'''

def find_accuracy(observed,predicted):
	correctly_classified=0
	for i in range(0,len(observed)):
		if(observed[i]==predicted[i]):
			correctly_classified=correctly_classified+1
	accuracy=correctly_classified/len(observed)
	return accuracy
			
sp=k_fold_validation(rows,6)
#print(sp[0])
tr,te=make_splits(sp)
#x=maxmin(rows)
#print(x)
"""

for i in range(len(te)):
	newcl=logistic_regression(tr,te,40,0.1)
	#print(newcl)
	te[i].append((newcl))
acc=find_accuracy(tr,te)
acc=acc*100
print(acc)
"""
'''
# evaluate algorithm
n_folds = 5
l_rate = 0.1
n_epoch = 100
scores = evaluate_algorithm(rows, logistic_regression, n_folds, l_rate, n_epoch)
print('Scores: %s' % scores)
print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))

'''
